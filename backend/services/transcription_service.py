import os
import numpy as np
import librosa
import warnings
from music21 import stream, note, instrument, clef, meter
from scipy.signal import find_peaks

warnings.filterwarnings("ignore")

async def transcribe_drums(audio_path, output_dir):
    """
    [Adaptive Sensitivity Version]
    ê°ì§€ëœ ë…¸íŠ¸ ìˆ˜ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ìë™ìœ¼ë¡œ ê°ë„ë¥¼ ì¡°ì ˆí•˜ì—¬ ì¬ì‹œë„í•©ë‹ˆë‹¤.
    """
    os.makedirs(output_dir, exist_ok=True)
    output_xml_path = os.path.join(output_dir, "transcription.musicxml")
    output_midi_path = os.path.join(output_dir, "transcription.mid")

    print(f"ğŸ¥ Transcribing (Adaptive): {audio_path}")

    try:
        # 1. ì˜¤ë””ì˜¤ ë¡œë“œ
        y, sr = librosa.load(audio_path, sr=44100)
        
        # ì •ê·œí™” (ê°€ì¥ í° ì†Œë¦¬ë¥¼ 1.0ìœ¼ë¡œ ë§ì¶¤)
        y = librosa.util.normalize(y)
        
        # íƒ€ì•…ê¸° ì„±ë¶„ ë¶„ë¦¬
        _, y_percussive = librosa.effects.hpss(y)
        
        # ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ì—ë„ˆì§€ ê³„ì‚° í•¨ìˆ˜
        def get_band_energy(y_input, low, high):
            S = np.abs(librosa.stft(y_input))
            fft_freqs = librosa.fft_frequencies(sr=sr)
            bins = np.where((fft_freqs >= low) & (fft_freqs <= high))[0]
            if len(bins) == 0: return np.zeros(S.shape[1])
            return librosa.util.normalize(np.mean(S[bins, :], axis=0))

        # 2. ëŒ€ì—­ë³„ ì—ë„ˆì§€ ì¶”ì¶œ
        env_kick = get_band_energy(y_percussive, 20, 150)
        env_snare = get_band_energy(y_percussive, 200, 2500)
        env_hh = get_band_energy(y_percussive, 5000, 20000)

        # 3. ì ì‘í˜• í”¼í¬ ê²€ì¶œ (Adaptive Peak Picking)
        def adaptive_pick(env, name, min_notes=20):
            # ì²˜ìŒì—ëŠ” ì¼ë°˜ì ì¸ ê¸°ì¤€(0.15)ìœ¼ë¡œ ì‹œë„
            thresholds = [0.15, 0.10, 0.05, 0.02] # ì ì  ì˜ˆë¯¼í•´ì§
            
            for th in thresholds:
                peaks, _ = find_peaks(env, height=th, distance=sr/16)
                if len(peaks) >= min_notes:
                    print(f"  - {name}: Found {len(peaks)} notes (Threshold: {th})")
                    return peaks
            
            # ê·¸ë˜ë„ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ê²°ê³¼ ë°˜í™˜
            print(f"  - {name}: Found {len(peaks)} notes (Warning: Low count)")
            return peaks

        peaks_kick = adaptive_pick(env_kick, "Kick")
        peaks_snare = adaptive_pick(env_snare, "Snare")
        peaks_hh = adaptive_pick(env_hh, "Hi-hat", min_notes=50) # í•˜ì´í–‡ì€ ë” ë§ì•„ì•¼ í•¨

        times_kick = librosa.frames_to_time(peaks_kick, sr=sr)
        times_snare = librosa.frames_to_time(peaks_snare, sr=sr)
        times_hh = librosa.frames_to_time(peaks_hh, sr=sr)

        # 4. ì•…ë³´ ìƒì„±
        s = stream.Score()
        p = stream.Part()
        p.id = 'DrumPart'
        p.insert(0, instrument.Percussion())
        p.insert(0, clef.PercussionClef())
        p.insert(0, meter.TimeSignature('4/4'))

        # 5. BPM ì¶”ì • ë° ê³ ì •
        try:
            tempo = librosa.feature.rhythm.tempo(y=y_percussive, sr=sr)[0]
        except:
            tempo = librosa.beat.tempo(y=y_percussive, sr=sr)[0]
            
        bpm = int(round(tempo))
        if bpm < 60 or bpm > 180: bpm = 120
        print(f"  - BPM: {bpm}")
        
        quarter_note_duration = 60.0 / bpm

        # 6. ë…¸íŠ¸ í†µí•© ë° í€€íƒ€ì´ì¦ˆ
        all_notes = []
        for t in times_kick: all_notes.append({'time': t, 'type': 'Kick', 'midi': 36})
        for t in times_snare: all_notes.append({'time': t, 'type': 'Snare', 'midi': 38})
        for t in times_hh: all_notes.append({'time': t, 'type': 'Hi-hat', 'midi': 42})
        
        all_notes.sort(key=lambda x: x['time'])

        # ì¤‘ë³µ ì œê±° (ë„ˆë¬´ ê°€ê¹Œìš´ ë…¸íŠ¸ ì‚­ì œ)
        filtered_notes = []
        last_time = -1
        for note_data in all_notes:
            if note_data['time'] - last_time > 0.05: # 50ms ì´ë‚´ ì¤‘ë³µ ë¬´ì‹œ
                filtered_notes.append(note_data)
                last_time = note_data['time']

        for note_data in filtered_notes:
            ql = note_data['time'] / quarter_note_duration
            quantized_ql = round(ql * 4) / 4.0
            
            n = note.Note()
            n.pitch.midi = note_data['midi']
            n.quarterLength = 0.25
            if note_data['type'] == 'Hi-hat': n.notehead = 'x'
            
            p.insert(quantized_ql, n)

        p.makeMeasures(inPlace=True)
        s.append(p)
        
        s.write('musicxml', fp=output_xml_path)
        s.write('midi', fp=output_midi_path)

        print(f"âœ… Custom Drum Transcription ì™„ë£Œ: {output_xml_path}")
        return output_midi_path, output_xml_path

    except Exception as e:
        print(f"âŒ Custom Transcription ì˜¤ë¥˜: {e}")
        return None, None